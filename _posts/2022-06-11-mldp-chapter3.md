---
title: "Chapter 3: 문제 표현 디자인 패턴"
categories:
  - Machine Learning Design Patterns
tags:
  - Study
  - Machine Learning
  - MLOps
gallery:
gallery:
  - url: /assets/images/머신러닝디자인패턴.jpg
    image_path: /assets/images/머신러닝디자인패턴.jpg
    alt: "placeholder image 1"
    title: "머신러닝 디자인패턴"
---

입력과 추력의 유형은 모델 아키텍처에 영향을 미치는 핵심 요소다. 특정 유형의 입력 데이터에 최적화된 특별한 신경망 계층도 있다. 합성곱 계층은 이미지, 음성, 텍스트 등 시공간 상관관계를 가지는 데이터에 잘 맞고, 순환 신경망은 시계열 데이터에 잘 맞는다.       
리프레이밍reframing 디자인 패턴은 회귀 문제를 분류 문제로 전환하거나, 반대로 분류 문제를 회귀 문제로 전환할 수 있다.       
멀티라벨multilabel 디자인 패턴은 학습 예제가 둘 이상의 클래스에 속하는 경우에 대처할 수 있으며, 캐스케이드cascade 디자인 패턴은 머신러닝 문제가 여러 단계의 연쇄적인 ML 문제로 나눠지는 상황을 위한 해결법이다. 앙상블ensemble 디자인 패턴은 다수의 모델을 학습시키고 그 응답을 집계하는 방식으로 문제를 해결하며, 중립 클래스neutral class 디자인 패턴은 전문가가 서로 동의하지 않는 상황을 취급한다. 리밸런싱rebalancing 디자인 패턴은 왜도가 큰 데이터나 불균형한 데이터를 처리하기 위한 접근 방법을 제시한다.       
         
--------------------------------------           
                   
## 3.1 디자인 패턴 5: 리프레이밍reframing               
리프레이밍reframing 디자인 패턴은 머신러닝 문제의 출력 표현을 바꾸는 방식이다. 회귀 문제로 보이는 문제를 분류 문제로 간주하거나, 분류 문제를 회귀 문제로 간주할 수 있다.        
            
### 문제              
머신러닝 솔루션을 만드는 첫 번째 단계는 문제에 대한 프레임을 세우는 일이다. 지도 학습인가, 비지도 학습인가? 지도 학습이라면 라벨은 무엇인가? 허용 오차는 어느 정도인가? 등등.           
*ex1. 어느 지역의 미래의 강우량을 예측하는 ml모델을 만든다고 할 때*         
*-> 시계열 기상 문제로 취급할 수도 있고, 강우량이라는 수치 라벨을 가진 회귀 문제로 취급할 수도 있다.*         
*-> 회귀 작업으로 강우량을 예측하는 대신 멀티클래스 분류를 사용하여 이산 확률 분포를 모델링 할 수 있다. (분류 문제로 리프레이밍)*             
*ex2. 동영상 추천 시스템을 구축 할 때*              
*-> 특정 비디오를 볼 가능성을 예측하는 분류 문제로 모델링할 수도 있지만,*             
*-> 시청할 비디오의 비율을 예측하는 회귀 문제로 리프레이밍하는 것이 더 나을 수도 있다.*            
                   
### 작동원리            
콘텍스트를 바꾸고 과제를 리프레이밍하는 것은 ml 솔루션 구축에 도움이 될 수 있다.           
                
* __회귀 모델 -> 분류 모델__                  
예측 대상을 하나의 수치가 아닌 이산 확률 분포로 만들면, 버킷화로 인해 정밀도는 약간 떨어지더라도 완전한 밀도 함수PDF라는 유연성을 얻게 된다. 분류 모델에서 제공하는 이산화된 예측은 유연성이 부족한 회귀 모델에 비해 복잡한 대상을 학습하는 데 더 적합하다. 또한, 예측값에 대해 보다 세부적인 정보를 제공하는 사후 확률 분포(posterior probability distribution)를 얻을 수도 있다.                      
주어진 문제를 리프레이밍하면 이산 확률 분포를 학습하는 멀티클래스 분류 모델을 학습시킬 수 있다. 이러한 이산화된 예측은 불확실성을 더 유연하게 포착하는 동시에, 회귀 모델에 비해 복잡한 목표를 더 잘 근사한다. 추론 시간 동안에 모델은 이러한 잠재적 출력에 상응하는 확률 모음을 예측한다. 즉, 특정 가중치의 상대적 가능성을 제공하는 개별 PDF를 얻게 된다. 여기서 주의를 기울여야 할 점은, 분류 모델의 경우 모델의 신뢰 수준이 너무 크거나 잘못되는 등 보정이 크게 틀어질 수 있다는 점이다.                     
                 
* __분류 모델 -> 회귀 모델__                 
사용자가 영화를 보고 1~5등급 내에서 평가를 남긴 대규모 영화 데이터베이스가 있고, 이를 바탕으로 사용자에게 추천 순위를 제공하는 데 사용할 머신러닝 모델을 만든다고 가정해보자.           
분류 모델을 가장 우선적으로 생각하겠지만, 이 과제를 회귀 작업으로 리프레이밍할 수도 있다. 회귀 작업으로 리프레이밍한 모델은 이제 주어진 영화에 대한 사용자 공간 표현을 예측한 후, 추천을 제공하기 위해 사용자의 알려진 특성에 가장 가까운 영화 세트를 선택한다. 즉, 사용자의 특정 영화에 대한 선호 확률을 계산하는 분류 과제에서 유사한 사용자들이 선호하는 영화의 클러스터를 회귀 작업을 통해 얻어내는 것이다. 영화 추천의 분류 문제를 사용자 특성의 회귀로 리프레이밍하면, 매번 별도의 분류 모델을 만들지 않아도 영상을 추천하는 추천 모델을 쉽게 조정할 수 있게 된다.               
이러한 모델 접근 방식은 수치 표현을 통해 직관적인 해석을 할 때도 유용하다.              
                   
### 트레이드오프와 대안               
리프레이밍 기법을 사용하는 경우 데이터의 한계 또는 라벨의 편향에 따른 위험이 존재한다는 점을 인식해야 한다.               
             
* __버킷화된 출력__                
회귀 작업을 분류 작업으로 리프레이밍하는 대표적인 방식은 출력값을 버킷화하는 것이다. -> 버킷화를 하면, 회귀 모델이 멀티클래스 분류가 된다.            
실제 출력값을 아주 정확히 예측하기보다는 적당한 오차를 허용하게 된다.             
                   
* __불확실성을 포착하는 다른 방법__              
회귀에서 불확실성을 포착하는 다른 방법도 있다.                 
분위수 회귀를 수행하거나,               
텐서플로 확률과 같은 프레임워크를 사용하거나, (이를 사용할 때는 출력 분포를 명시적으로 모델링해야 한다)             
람다 함수를 사용하는 방법 등이다.               
           
```
TIP               
머신러닝 모델 학습의 핵심은 데이터다. 데이터의 관계가 복잡할수록 파악이 어려운 패턴을 찾기 위하여 더 많은 학습 데이터가 필요하다.       
분류 작업에 대한 일반적인 경험 법칙은 각 라벨 카테고리에 대해 모델 특징 개수의 10배의 데이터를 가져야 한다는 것이다.       
회귀 모델의 경우에는 모델 특징 수의 50배다. 물론 이러한 수치는 대략적인 시행착오에 의한 부정확한 추정치이지만,        
보편적으로 회귀 작업이 더 많은 학습 데이터를 필요로 한다는 것은 명백한 사실이다. 게다가 대규모 데이터에 대한 수요는 작업의 복잡도에 따라 증가한다.         
따라서 사용할 모델의 유형에 따라 필요한 데이터의 양은 달라지며 분류 작업의 경우 라벨 카테고리의 수를 감안해야 한다.          
```             
         
#### 예측의 정밀도           
회귀 모델을 멀티클래스 분류로 리프레이밍하는 경우, 출력 라벨에 대한 전체 빈의 너비가 분류 모델의 정밀도를 좌우하게 된다.             
PDF의 뾰족한 정도는 회귀 작업의 정밀도를 나타낸다. PDF가 뾰족하면 출력 분포의 표준편차가 작은 것이고, PDF가 뭉툭하면 표준편차가 큰 것이다. 그러므로 매우 뾰족한 PDF를 가진 데이터에는 회귀 모델을 사용하는 것이 좋다.             
![KakaoTalk_20220609_135609936](https://user-images.githubusercontent.com/104043279/172767600-0cbf560e-7bfd-48ed-924d-034ddc0f278d.jpg)             
           
#### 예측 범위 제한하기           
예측 출력의 범위를 제한해야 하는 경우에도 문제를 리프레이밍하는 것이 도움이 된다.            
         
#### 라벨 편향               
행렬 분해와 같은 추천 시스템은 회귀로도 분류로도 리프레이밍할 수 있다. 리프레이밍의 한 가지 장점은 회귀 또는 분류 모델로 구성된 신경망이 행렬 분해에서 학습한 사용자와 항목의 임베딩 외에도 더 많은 추가적인 특징을 통합할 수 있다는 점이다.       
그러나 문제를 리프레이밍할 때는 대상 라벨의 특징을 고려하는 것이 중요하다. 라벨을 변경하거나 머신러닝 모델을 학습할 때에는 실수로 솔루션에 라벨 편항을 도입하지 않도록 유의해야 한다.        
          
#### 멀티태스크 학습          
멀티태스크 학습은 리프레이밍의 대안이라고도 볼 수 있다. 회귀 또는 분류 중 하나를 선택하는 대신 둘 다 선택하자는 것이다. 일반적으로 멀티태스크 학습은 둘 이상의 손실 함수가 최적화된 모든 ml 모델을 지칭한다. 여러 가지 방법이 있지만 신경망에서 가장 일반적인 두 가지 형태의 멀티태스크 학습은 아래와 같다.       
* 하드 파라미터 공유        
* 소프트 파라미터 공유       
           
파라미터 공유는 회귀, 분류와 같이 서로 다른 출력 작업에서 신경망의 파라미터를 공유하는 것을 말한다. 하드 파라미터 공유는 모든 출력 작업이 모델의 숨겨진 계층을 공유하는 것을 가리킨다. 소프트 파라미터 공유는 각 라벨이 자체 신경망과 파라미터를 가지고 있으며, 서로 다른 여러 모델의 파라미터가 일정 형태의 정규화 과정을 통하여 유사하게 유도되는 구조를 말한다.          
![hard_soft](https://user-images.githubusercontent.com/104043279/172768692-90f02cb8-233e-4826-9bae-960bb72aed83.jpg)             
요컨대 파라미터 공유를 통해 여러 작업을 동시에 학습시키면 두 손실 함수의 기울기에서 업데이트된 출력과 결과를 모두 알 수 있고, 이는 보다 일반화된 모델로 쓰일 수 있다.           
                       
----------------------------------------                      
                   
## 3.2 디자인 패턴 6: 멀티라벨multilabel             
멀티라벨multilabel 디자인 패턴이란 주어진 학습 데이터에 둘 이상의 라벨을 할당할 수 있는 문제를 말한다. 보통 모델의 예측 작업에는 주어진 학습 예제를 하나의 클래스로 분류하는 작업이 많다. 하지만 각 학습 예제에 2개 이상의 라벨을 할당할 수 있는 경우에 멀티라벨 디자인 패턴이 사용된다.         

### 솔루션         
주어진 학습 예제에 둘 이상의 라벨을 할당할 수 있는 모델을 구축하기 위해서는 최종 출력 계층에 시그모이드 활성화 함수를 사용하면 된다. 모든 값의 합이 1인 배열을 생성하는 소프트맥스의 경우와 달리, 시그모이드 배열의 각 개별값은 0과 1 사이의 범위를 가지는 부동 소수점값이다. 즉, 멀티라벨 디자인 패턴을 구현하려면 라벨은 멀티-핫 인코딩이 되어야 한다. 멀티-핫 배열의 길이는 모델의 클래스 수에 해당되며 이 라벨 배열의 각 출력은 시그모이드값이 된다.            
            
```             
<시그모이드 함수 vs. 소프트맥스 함수>          
시그모이드는 ml모델의 이전 계층에 있는 각 뉴런의 출력을 가져와 그것들을 0과 1 사이로 납작하게 늘린 형태의        
비선형, 연속, 미분 가능한 활성화 함수다. 시그모이드는 하나의 값을 받고 하나의 값을 출력하는 반면,         
소프트맥스는 값의 배열을 입력으로 받고 확률 배열을 출력하며 출력 배열의 모든 원소의 합이 1이 된다.         
일련의 시그모이드 출력을 소프트함수에 대한 입력으로 전달하는 것도 가능하다.           
```            
        
### 트레이드오프와 대안         
* 두 클래스에 걸친 모델의 시그모이드 출력        
출력이 두 클래스에 속할 수 있는 모델에는 두 가지 유형이 있다.     
1. 멀티클래스 분류 - 이진 분류       
모든 학습 예제는 단 1개의 라벨만을 가진다.        
N 클래스의 수 = 2              
2. 멀티라벨 분류        
각 예제가 여러 라벨을 가질 수 있다.             
            
1의 경우(이진 분류)는 활성화 함수로 시그모이드를 사용하는 단일 라벨 분류 문제에 대한 유일한 형태라는 점에서 독특하다. 거의 모든 멀티클래스 분류 문제가 소프트맥스를 사용하는 반면, 2개의 클래스만 있는 경우에는 소프트맥스까지 필요하지 않다. 이진 분류 모델에 있어 최적의 방안은 시그모이드 활성화 함수와 함께 형태가 1인 출력 형태를 사용하는 것이다.       
2의 경우(멀티라벨)는 형태가 2인 출력으로 시그모이드를 사용하면 된다.        
       
* __어떤 손실 함수를 사용할까?__      
모델이 하나의 원소만 출력하는 이진 분류의 경우 이진 크로스 엔트로피 손실(binary cross-entropy loss)이 좋다. 시그모이드 출력이 있는 멀티라벨 모델에서도 이진 크로스 엔트로피 손실을 쓸 수 있다.         
            
* __시그모이드 결과 파싱하기__         
소프트맥스 출력 모델에서 예측 라벨을 추출하려면 예측을 얻기 위한 출력 배열의 최댓값 변수를 취하면 된다. 시그모이드 출력을 분석하는 것은 조금 더 복잡하다. 예측 확률이 가장 높은 클래스를 선택하는 대신, 출력 계층에서 각 클래스의 확률을 평가하고 상황에 대한 확률 임계값을 고려해야 한다. 여기에서의 임곗값이란 어떤 입력이 특정 클래스에 속하는지를 확신할 수 있는 확률이다. 임곗값은 모든 종류의 분류 모델에 대해 검토해야 할 사항이지만, 각 클래스의 서로 다른 임곗값을 결정해야 하기 때문에 멀티라벨 디자인 패턴과 특히 관련이 있다.      
※임곗값을 보다 정확히 결정하려면 S-Cut을 사용하거나 모델의 F-measure를 최적화시키는 편이 좋다.        
          
* __데이터셋 고려 사항__          
멀티라벨 디자인 패턴을 활용할 때에는 단일 라벨 분류 작업에서보다 더 섬세하게 균형 잡힌 데이터셋을 구축하도록 노력해야 한다.        
       
* __라벨이 겹치는 입력__
멀티라벨 디자인 패턴은 입력 데이터에 간혹 겹치는 라벨이 있을 때도 유용하다. 각 학습 데이터 항목에 대해 복수의 라벨이 맞게 지정되었을 때, 멀티라벨 디자인 패턴은 서로 다른 두 라벨을 하나의 이미지에 연관시켜 이 문제를 해결한다.          
          
* __OVR__             
멀티라벨 분류를 처리하는 또 다른 기술은 하나의 멀티라벨 모델 대신 여러 이진 분류기를 학습하는 것이다. 이 접근 방식을 OVR(one versus rest)이라고 한다.          
OVR의 이점은 서포트 벡터 머신(SVM)과 같이 이진 분류만 수행할 수 있는 모델 아키텍처와 함께 쓸 수 있다는 점이다. 모델이 각 입력에 대해 한 번에 하나의 분류 작업만 수행하기 때문에 희귀한 카테고리에도 도움이 도리 수 있으며 리밸런싱 디자인 패턴을 적용할 수도 있다. 이 방식의 단점은 하나의 모델만 사용하는 것이 아니라 각각의 모델에서 예측을 생성하는 방식으로 애플리케이션을 구축하면서 여러 분류기에 대한 학습이라는 복잡성이 더해진다는 점이다.           
           
요약하면 데이터가 다음 분류 시나리오 중 하나에 해당하는 경우 멀티라벨 디자인 패턴을 사용한다.            
1. 하나의 학습 예제가 서로 배타적인 복수의 라벨과 연결될 수 있다.        
2. 하나의 학습 예제에 여러 계층적 라벨이 있을 수 있다.        
3. 라벨 지정자들이 같은 항목의 라벨을 서로 다르게 지정하는데, 이러한 라벨이 모두 알맞다.         
           
멀티라벨 모델을 구현할 때는 겹치는 라벨의 조합이 데이터셋에서 잘 표현되는지를 확인해야 한다. 또한 모델의 가능한 각 라벨에 대해 허용할 임곗값을 잘 결정해야 한다. 시그모이드 출력 계층을 사용하는 것은 멀티라벨 분류를 처리하는 모델을 만들기 위한 가장 일반적인 방법이다. 시그모이드 출력은 이진 분류 작업에도 적용할 수 있다.            
                       
----------------------------------------                      
                   
## 3.3 디자인 패턴 7: 앙상블ensemble             
앙상블ensemble 디자인 패턴은 여러 ml모델을 결합하고 그 결과를 집계하여 예측하는 기술을 나타낸다. 앙상블은 성능을 개선하고 단일 모델보다 더 나은 예측을 만들기 위한 효과적인 수단이 될 수 있다.               
          
### 문제          
완벽한 머신러닝 모델은 없다. ml 모델의 오류를 다음과 같이 나눌 수 있다.           
1. 줄일 수 없는 오류(irreducible error)          
데이터셋의 노이즈나 문제의 프레임 같은 모델의 내재적 오류, 또는 측정 오류나 혼재 요인confounding factor과 같은 잘못된 학습 예제로 인해 발생한다. 조치할 수 있는 부분이 거의 없다.        
2. 줄일 수 있는 오류(reducible error)         
편향으로 인한 오류, 분산으로 인한 오류가 여기에 속한다. 편향은 모델이 특징과 라벨 간의 관계에 대해 충분히 학습할 수 없게 만드는 요소고, 분산은 보이지 않는 새로운 예에 대해 일반화할 수 없게 만드는 요소다.       
편향이 높은 모델은 관계를 과도하게 단순화했기에 과소적합이라고 한다. 분산이 높은 모델은 학습 데이터에 대해 너무 많이 학습했기에 과대적합이라고 한다. ml 모델의 목표는 낮은편향&낮은분산이지만 동시에 만족하기란 어렵다.       
ex.모델 복잡성을 늘리면 편향은 감소하지만 분산이 증가하는 반면, 모델 복잡성을 줄이면 분산은 감소하지만 편향이 증가한다.      
             
### 솔루션             
앙상블 방법은 편향과 분산을 줄이고 모델 성능을 개선하기 위한 기술로, 여러 ml모델을 결합하는 메타 알고리즘이다. 배깅, 부스팅, 스태킹 등이 일반적이다.            
          
* __배깅bagging__            
배깅bagging (부트스트랩 집계bootstrap aggregating의 약자) 은 일종의 병렬 앙상블 방법으로, ml모델의 높은 분산을 해결하는 데 사용된다. 배깅 앙상블 방법의 좋은 예는 랜덤 포레스트다. 전체 학습 데이터셋을 무작위로 샘플링한 하위 집합에서 여러 결정 트리를 학습시킨 다음, 트리 예측을 집계하여 예측을 생성한다.       
![bagging](https://user-images.githubusercontent.com/104043279/172780741-2f8c85a8-c4a6-49dc-ad47-b6a2517129c7.png)           
           
* __부스팅boosting__          
부스팅boosting은 배깅과 달리 궁극적으로 개별 구성원 모델보다 더 많은 용량을 가진 앙상블 모델을 구성한다. 그래서 부스팅은 분산보다는 편향을 줄이는 데 효과적이다. 부스팅의 기본적인 아이디어는 이전의 모델이 잘못 학습한 학습 데이터를 후속 모델이 제대로 학습할 수 있도록 일련의 모델 앙상블을 반복적으로 구축하는 것이다. 요컨대, 부스팅은 강한 학습기를 만들기 위해 가중 평균을 사용하는 일련의 약한 학습기를 반복적으로 개선한다.       
![boosting](https://user-images.githubusercontent.com/104043279/172781392-cc9a0039-d511-4af9-8fab-74f51438ed1c.png)          
         
* __스태킹stacking__         
스태킹stacking은 예측을 위해 여러 모델의 출력을 결합하는 앙상블 방법이다. 스태킹은 학습 데이터셋에서 k개의 모델을 학습시킨 다음 결과를 평균하여 예측을 결정하는 **단순 모델 평균화**의 확장으로 볼 수 있다. 단순 모델 평균화는 배깅과 유사하지만, 배깅에서는 앙상블의 개별 모델이 모두 동일한 반면, 단순 모델 평균화에서는 서로 다른 유형일 수 있다. 또한, 단순 모델 평균화에서는 가중 평균을 취하도록 평균화 단계를 수정할 수 있다. 스태킹은 평균 또는 가중 평균을 취하는 대신, 두 번째 ml모델을 학습시켜 앙상블의 각 모델 결과를 가장 잘 결합하는 방법을 학습하게 한다.            
           
### 작동 원리             
이상적인 상황에서는 각 개별 모델이 임의의 양만큼의 오류를 가지므로 배깅을 통해 그 결과를 평균화하면 임의의 오류가 상쇄되고 예측이 정답에 더 가까워진다.            
부스팅은 각 반복 단계에서 잔차에 따라 모델에 패널티를 가하는 방식으로 작동한다. 반복할 때마다 앙상블 모델은 예측하기 어려운 예제를 더 잘 예측할 수 있도록 개선된다.         
스태킹은 배깅과 부스팅의 장점을 모두 결합한 것으로 스태킹의 2차 모델은 모델 평균화보다 정교한 버전으로 볼 수 있다. 분산 감소의 이점을 취할 뿐아니라 높은 편향을 제어한다.        
             
### 트레이드오프와 대안             
* __늘어난 학습 시간과 설계 시간__            
앙상블 학습의 한 가지 단점은 학습 및 설계 시간이 늘어난다는 점이다. 앙상블 모델이 프로덕션에 투입되면 유지 관리, 추론의 복잡성, 리소스 사용량 증가, 모델 개발 비용 및 시간 증가 등의 문제가 생겨난다. 따라서 앙상블 방법을 채택하면서 증가한 비용과 시간을 잘 따져보고 그만한 가치가 있는지를 신중하게 고려해야 한다.              
             
* __드롭아웃을 통한 배깅__            
드롭아웃dropout은 흔히 딥러닝 정규화 기술로 알려져 있지만, 배깅의 대체재로도 간주할 수 있다. 드롭아웃은 신경망에서 학습의 각 mini-batch에 대해 네트워크의 뉴런을 무작위로(미리 규정된 확률로) turns off하는 방법으로서, 이를 통해 기하급수적으로 많은 신경망의 배깅 앙상블을 평가할 수 있다.           
다만, 드롭아웃으로 신경망을 학습시키는 것이 배깅과 정확히 같지는 않다. 배깅의 모델은 독립적인 반면 드롭아웃으로 학습할 때는 모델이 파라미터를 공유한다. 또, 배깅의 모델은 각각의 학습 데이터셋에서 수렴할 때까지 학습하지만 드롭아웃으로 학습할 때는 한 번의 학습 단계만 거친다.          
              
* __모델 해석 가능성의 감소__        
앙상블의 또 다른 문제점은 모델 해석 가능성이다. 안 그래도 효과적으로 설명하기 어려운 딥러닝 모델이 앙상블을 거치면 더 복잡해진다.           
          
* __문제에 맞는 도구 선택하기__       
상관관계가 높은 오류가 있는 두 모델을 결합하는 것은 분산을 낮추는 데 도움이 되지 않는다. 요컨대, 앙상블 방법을 사용한다고 해서 반드시 성능이 향상되는 것은 아니라는 뜻이다. 잘못 사용하면 시간과 비용이 불필요하게 늘어날 뿐이다.          
                       
----------------------------------------                      
                   
## 3.4 디자인 패턴 8: 캐스케이드cascade             
캐스케이드cascade 디자인 패턴은 머신러닝 문제를 일련의 ml문제로 나누어 유리한 상황에 사용할 수 있음을 보여준다.      
        
### 문제         
일상적인 활동과 비정상적인 활동 모두에서 값을 예측해야 할 때, 비정상적인 활동은 그 수가 적기 때문에 모델은 이를 무시하는 법을 학습할 것이다. 특히 비정상적인 활동이 비정상적인 값으로 이어진다면 학습 가능성은 더욱 낮아진다.           
이 문제를 해결하는 직관적인 방법이 바로 캐스케이드 디자인 패턴을 사용하는 것이다.           
          
### 솔루션          
캐스케이드는 한 모델의 출력이 다음 모델에 대한 입력이 되거나 후속 모델의 선택을 결정하는 모든 ml 문제를 일컫는다. 캐스케이드 ml 모델을 학습할 때는 특별한 주의가 필요하다.             
예를 들어 가끔 비정상적인 상황을 수반하는 ml 문제는 다음과 같이 이어지는 네 가지의 머신러닝 문제로 해결할 수 있다.          
* 상황을 식별하는 분류 모델     
* 비정상적인 상황에서 학습된 하나의 모델         
* 일반적인 상황에서 학습된 별도의 모델        
* 최종 출력은 두 출력의 확률적 조합이기 때문에, 2개의 개별 모델의 출력을 결합하는 모델          
               
```            
ex. 자전거 대여소와 반납소 사이의 거리를 예측하려고 한다. 장기 대여 사용자의 행동은 단기 대여 사용자의 행동과 매우 다르고,        
수가 극소로 적다. 이 때, 실제 대여 기간을 기준으로 학습 데이터셋을 두 부분으로 나누고 두 모델을 만든다. 그 후 하나는 장기       
대여에 대해, 다른 하나는 일반 대여에 대해 학습시키는 접근 방법을 쉽게 떠올릴 수 있다. 하지만 이 분류 모델에는 오류가 있다.       
실제로 테스트 데이터셋으로 모델을 평가하면 정확도가 약 75%에 불과하다는 것을 알 수 있다. 이 정도 정확도를 가지고 데이터를       
완전히 분할해서 두 모델을 학습하는 것은 옳은 방법은 아닐 것이다. 대신, 분류 모델을 학습한 후 이 모델의 예측을 사용하여       
다음 모델셋에 대한 학습 데이터셋을 만들어야 한다.              
```          
         
캐스케이드 워크플로를 제대로 유지하는 것은 어려운 일이다. 모델을 개별적으로 학습하는 것보다는, 워크플로 파이프라인 패턴을 사용하여 전체 워크플로를 자동화하는 것이 좋다. 핵심은 업스트림upstream 모델의 예측을 기반으로 실험이 실행될 때마다 2개의 다운스트림 모델에 대한 학습 데이터셋이 생성되도록 하는 것이다.         
일상적인 활동과 비정상적인 활동 모두에서 값을 예측하는 방법에서 뿐만 아니라, 캐스케이드 패턴은 보다 일반적인 상황을 처리할 수도 있다. 파이프라인 프레임워크를 사용하면 머신러닝 문제를 일련의 여러 ml문제로 나누어 유리한 모든 상황을 처리할 수 있다.          
           
### 트레이드오프와 대안           
캐스케이드는 머신러닝 워크플로를 복잡하게 만들고, 이로 인해 실제 긴으이 저하될 수 있다. 때문에 가능한 한 하나의 파이프라인(수집, 전처리, 데이터 유효성 검사, 변환, 학습, 평가, 배포)에는 하나의 머신러닝 문제를 할당해야 한다. 캐스케이드 패턴과 같이 동일한 파이프라인에 여러 머신러닝 모델을 사용하지 않는 것을 권장한다.     
* __결정론적 입력__       
ml 모델의 목적은 여러 요인을 조합하는 것이기 때문에 일반적으로 ml 문제를 여러 단계로 분할하는 것은 좋은 생각이 아니다.       
캐스케이드 디자인 패턴은 카테고리형 입력이 없으면서 여러 입력에서 극값을 학습해야 하는 비정상적인 시나리오를 다룬다.       
        
* __단일 모델__          
단일 모델로 충분한 일반적인 시나리오에는 캐스케이드 디장니 패턴을 사용하면 안 된다.              
            
* __내부 일관성__            
캐스케이드는 여러 모델의 예측 간에 내부 일관성을 유지해야 할 때 필요하다. 여기에서는 비정상적인 활동을 예측하는 것 이상을 시도한다.          
               
* __사전 학습된 모델__             
사전 학습된 모델의 출력을 다른 모델의 입력으로 재사용하려는 경우에도 캐스케이드가 필요하다.        
          
* __캐스케이드를 리프레이밍으로 대체__          
               
* __희귀한 상황에서의 회귀__        
캐스케이드는 디자인 패턴은 일부 값이 다른 값보다 훨씬 더 일반적인 데이터를 바탕으로 회귀를 수행할 때 유용하다.          
                       
----------------------------------------                      
                   
## 3.5 디자인 패턴 9: 중립 클래스neutral class             
중립 클래스neutral class 디자인 패턴은 많은 분류 과제에서 도움을 준다.              
ex. 이벤트 확률을 출력하는 이진 분류기를 학습하는 대신, '예'/'아니오'/'아마도'라는 세 가지의 배반 확률(disjoint probability)을 출력하는 3개의 클래스 분류기를 학습시킬 수 있다. 여기서 배반 확률이란 클래스가 겹치지 않음을 의미한다. 학습 패턴은 하나의 클래스에만 속할 수 있으므로, '예'와 '아마도'는 겹치지 않는다. 이 경우 '아마도'가 중립 클래스에 해당된다.           
           
### 트레이드오프와 대안           
중립 클래스 디자인 패턴은 머신러닝 문제를 처음 디자인할 때부터 염두에 두어야 할 패턴이다. 다음은 중립 클래스가 도움이 될 수 있는 몇 가지 상황이다.           
1. 전문가의 의견이 일치하지 않을 때         
2. 고객 만족도를 예측하려 할 때           
3. 임베딩의 개선         
4. 중립 클래스의 리프레이밍           
ex. 주식의 상승/하락 여부에 따라 거래를 수행하는 자동 거래 시스템을 학습한다고 가정해보자. 주식 시장의 변동성과 새로운 정보가 주가에 반영되는 속도로 인해, 작은 상승 및 하락 예측을 바탕으로 거래를 시도하면 시간이 지남에 따라 거래 비용은 높아지고 수익은 낮아질 것이다. 이 때 다음 세 가지 클래스로 구성된 학습 데이터셋을 만드는 것이 솔루션이 된다.           
- 5% 이상 상승한 주식: 콜            
- 5% 이상 하락한 주식: 풋           
- 나머지 주식: 중립 카테고리                      
이처럼 주식이 얼마나 올라갈지에 대한 회귀 모델을 학습하는 대신, 중립 클래스를 포함한 세 가지 클래스로 분류 모델을 학습한다면 가장 확실한 예측을 선택할 수 있다.         
                       
----------------------------------------                      
                   
## 3.6 디자인 패턴 10: 리밸런싱rebalancing             
리밸런싱rebalancing 디자인 패턴은 불균형한 데이터셋을 처리하기 위한 다양한 접근 방식을 포함한다. **불균형한 데이터셋: 하나의 라벨이 데이터셋의 대부분을 구성하고 다른 라벨의 예가 훨씬 적은 데이터셋*           
이 디자인 패턴은 데이터셋에서 특정 인구 또는 실제 환경에 대한 표현이 부족한 시나리오를 다루지는 않는다. -> 이 경우는 추가 데이터 수집을 통해서만 해결가능.      
리밸런싱 디자인 패턴은 주로 특정 클래스에 대한 예제가 거의 없는 데이터셋으로 모델을 만드는 방법을 다룬다.        
           
### 문제            
ml 모델은 데이터셋의 각 라벨 클래스마다 유사한 수의 예제가 제공될 때 가장 잘 학습한다. 그러나 많은 경우, 실제 데이터셋은 균형이 잘 맞지 않는다. 회귀 모델에 불균형 데이터셋을 넣으면, 데이터셋의 중앙값보다 훨씬 높거나 낮은 아웃라이어값을 가진 데이터를 볼 수 있다. 불균형 라벨 클래스를 사용하는 학습 모델의 일반적인 함정은, 모델 평가 후 잘못된 정확도값에 의존하는 것이다. (=정확도가 높게 나올 순 있으나, 이는 모델이 입력 데이터를 과반수 클래스로 분류하기 때문일 수 있다.) 이렇게 오해의 소지를 가지는 정확도값에 너무 의존하지 않으려면, 모델의 오차행렬을 살펴보고 각 클래스의 정확도를 확인하는 것이 좋다.       
        
### 솔루션          
불균형한 데이터셋으로 학습시킨 모델의 정확도에는 오해의 소지가 있으므로 모델을 만들 때 적절한 평가 측정 항목을 선택하는 것이 중요하다. 데이터셋과 모델 수준 모두에서 불균형한 데이터셋을 처리하기 위해 사용할 수 있는 다양한 기술이 있다.      
다운샘플링downsampling은 기본 데이터셋의 균형을 바꾸는 기법이며, 가중치 부여weighting는 모델이 특정 클래스를 처리하는 방식을 바꾼다. 업샘플링upsampling은 소수 클래스의 예제를 복제하며 추가 샘플을 생성하는 데이터 증식 기법이다. 또한 문제를 리프레이밍하는 접근방식인 회귀 작업으로 바꾸기, 각 예제에 대한 모델의 오류값 분석, 클러스터링 등도 있다.          
          
* __평가 지표 설정하기__          
불균형 데이터셋에서는 정밀도, 재현율 또는 F값(F-measure)과 같은 축정 항목을 사용하여 모델의 성능을 완벽하게 파악하는 것이 가장 좋다.         
  - 정밀도: 모델에서 수행한 모든 긍정 예측 중에서 실제로 긍정에 해당하는 분류의 백분율을 측정한 값. 분모=모델이 만든 긍정 클래스 예측의 총수        
  - 재현율: 실제로 긍정에 해당하는 모든 데이터 중 모델이 긍정으로 예측한 데이터의 비율을 측정한 값. 분모=데이터셋 내에 있는 실제 긍정 클래스 예제의 총수       
  - F값: 0~1 사이의 측정 항목. 정밀도와 재현율을 모두 고려. 2 * (precision * recall / (precision + recall))         
        
  불균형 데이터셋으로 학습시킨 모델을 평가하고 성공 지표를 계산할 때는 샘플링되지 않은 데이터(unsampled data)를 사용해야 한다. 학습용 데이터셋을 수정하는 리밸런싱 방법과 관계없이, 테스트셋은 원래의 데이터셋과 거의 동일한 클래스 균형을 가져야 한다.          
            
* __다운샘플링__       
다운샘플링은 모델이 아닌 기본 데이터셋을 변경하여 불균형 데이터셋을 처리하는 방법이다. 다운샘플링을 사용하면 모델 학습 중에 사용되는 대다수 클래스의 예제 수를 줄인다.       
대규모 데이터셋은 보통 모델의 패턴 식별 능력을 향상시킬 수 있지만, 데이터가 크게 불균형한 경우에는 대규모라는 특징이 그다지 유용하지 않다. 불균형 데이터가 있을 때, 소수 클래스의 데이터를 모두 가져와서 모델 학습 시 사용할 수 있도록 따로 설정한다. 그 후 과반수 클래스의 데이터 무작위 샘플을 조금만 가져온다. 그런 다음 소수 클래스의 모든 데이터를 결합하고 데이터를 리프레이밍한 다음 새롭게 구성된 작은 데이터셋을 사용하여 모델을 학습시킨다.          
다운샘플링은 일반적으로 다음 단계에 따라 앙상블 패턴과 결합된다.        
1. 과반수 클래스를 다운샘플링하고 소수 클래스의 모든 인스턴스를 사용한다.         
2. 모델을 학습시키고 앙상블에 추가한다.         
3. 반복한다.        
추론하는 동안에는 앙상블 모델의 중간값을 취한다.      
         
* __가중치를 부여한 클래스__        
불균형 데이터셋을 처리하는 또 다른 방식은 모델이 각 클래스의 예제에 제공하는 가중치를 변경하는 것이다. 클래스에 가중치를 부여하여 학습 중에 특정 라벨 클래스를 더 중요하게 취급하도록 모델에 지시하는 방식으로, 모델이 소수 클래스의 예에 더 많은 가중치를 할당할 수 있다.          
           
* __업샘플링__
업샘플링을 사용하면 소수 클래스 예제를 복제하고 추가 합성 예제를 생성하여 소수 클래스의 표현을 확장할 수 있다. 이 기법을 과반수 클래스의 다운샘플링과 함께 쓰는 경우도 많다.    
             
```           
SMOTE(Synthetic Minority Over-sampling Technique):         
다운샘플링과 업샘플링을 결합한 방식.           
데이터셋에서 소수 클래스 예제의 특징 공간을 분석하여 합성 예제를 구성한 다음, 최근접 이웃 접근법을 사용하여       
이 특징 공간 내에서 유사한 예제를 생성하는 알고리즘.       
한 번에 고사할 유사 데이터 포인트의 수(최근접 이웃 수)에 따라 이러한 포인트 사이에 새로운 소수 클래스 예제를 무작위로 생성한다.           
```            
          
### 트레이드오프와 대안         
* __리프레이밍과 캐스케이드__         
문제를 리프레이밍하는 것은 불균형 데이터셋을 처리하는 또 다른 접근 방식이다. 리프레이밍 디자인 패턴을 활용하여 문제를 분류에서 회귀로, 또는 그 반대로 전환하는 것을 고려할 수 있으며 여기에 더해서 모델의 캐스케이드 학습을 수행할 수 있다.        
          
* __이상 탐지__         
불균형 데이터셋을 가진 회귀 모델을 처리하는 방법에는 두 가지가 있다.       
  - 모델의 예측 오류를 신호로 사용: 스트리밍, 시계열 데이터 관련 문제에 적합        
  - 들어오는 데이터를 클러스터링하고, 새 데이터 포인트와 기존 클러스터와의 거리를 비교        
          
* __사용 가능한 소수 클래스 예제의 수__       
소수 클래스의 예가 너무 적은 데이터셋에서 다운샘플링으로 모델을 학습시키려면 결과 데이터셋이 너무 작아지게 된다. 다운샘플링을 사용하기에 너무 적은 예가 몇 개인지를 결정하는 규칙은 없으나, 일반적으로 소수 클래스의 데이터 포인트가 수백 개뿐이라면, 데이터셋 불균형을 처리하기 위해 다운샘플링 이외의 솔루션을 고려하는 것이 좋다.           
또한 과반수 클래스의 하위 집합을 제거하면 자연스럽게 해당 예제에 저장된 일부 정보가 손실된다는 점도 주목해야 한다. 이로 인해 과반수 클래스를 식별하는 모델의 기능이 약간 저하될 수도 있지만, 보통은 다운샘플링의 이점이 이를 상쇄한다.       
         
* __서로 다른 기법의 결합__        
다운샘플링과 클래스 가중치 부여 기술을 결합하거나, 다운샘플링을 앙상블 디자인 패턴과 결합하는 등 서로 다른 기술들을 결합하여 최적의 결과를 얻을 수도 있다.         
이러한 데이터 중심 접근 방식을 결합하는 것 외에도, 정밀도 또는 재현율을 최적화하기 위해 분류기의 임곗값을 조정할 수도 있다.             
         
* __모델 아키텍처 선택__         
서로 다른 모델 아키텍처를 실험해서 불균형 데이터에서 가장 좋은 성능을 내는 것이 무엇인지 확인하며 프로젝트를 진행해나가야 한다.         
           
* __설명 가능성의 중요성__          
이상치와 같이 데이터에서 드물게 발생하는 항목을 찾아내는 모델을 만들 때는 모델이 예측을 수행하는 방식을 이해하는 것이 특히 중요하다. 이러한 이해가 있어야 모델이 올바른 신호를 포착하여 예측을 수행하는지 확인하고 최종 사용자에게 모델의 동작을 설명할 수 있다.          
모델에 대한 설명은 여러 형태를 취할 수 있으며, 그중 대표적인 개념으로 **기여값(attribution value)**이 있다. 기여값은 모델의 각 특징이 모델의 예측에 얼마나 영향을 미쳤는지를 알려준다. 기여값이 양수이면 해당 특징이 모델의 예측을 끌어올렸음을 의미하고, 기여값이 음수이면 특징이 모델의 예측을 끌어내렸음을 의미한다. 기여값의 절댓값이 클수록 모델의 예측에 더 큰 영향을 미쳤다고 볼 수 있다.        
설명은 모든 유형의 ml 모델에서 중요하지만, 리밸런싱 디자인 패턴을 따르는 모델에서 특히 유용하다. 불균형 데이터를 처리할 때는 모델의 정확도와 오류 지표를 넘어서 데이터에서 의미 있는 신호를 포착하고 있는지 확인하는 것이 중요하다.         
                 
                
